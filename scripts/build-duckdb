#!/usr/bin/env bash

set -eo pipefail

SCRIPT_NAME=$(basename "$0")

usage() {
    printf "%s <input.json> <output.duckdb>\n" "${SCRIPT_NAME}"
    exit 1
}

require_bin() {
    if which "${1}" >/dev/null; then
        return 0
    fi
    printf "missing binary: %s\n" "${1}"
    exit 1
}

require_file() {
    # one argument only
    if [[ $# != 1 ]]; then
        printf "%s: supply a single file argument\n" "${0}"
        exit 1
    fi
    
    # check file existence
    if [[ -f "${1}" ]]; then
        return 0
    fi
    printf "file not found: %s\n" "${1}"
    exit 1
}

require_no_file() {
    if [[ -f "${1}" ]]; then
        printf "file already exists: %s\n" "${1}"
        exit 1
    fi
    return 0
}

create_database() {
    local db_path=$1

    # overwrite if exists, so pass a temp file to this function
    if [[ -f "${db_path}" ]]; then
        rm "${db_path}"
    fi

    read -r -d '' schema_query <<- 'EOF'
        create table posts(did varchar, cid varchar, created_at varchar, text varchar);
EOF
    #     read -r -d '' schema_query <<- 'EOF'
    # CREATE TABLE posts(did VARCHAR, cid VARCHAR, feedpost STRUCT("$type" VARCHAR, createdAt VARCHAR, embed STRUCT("$type" VARCHAR, images STRUCT(alt VARCHAR, aspectRatio STRUCT(height BIGINT, width BIGINT), image STRUCT("$type" VARCHAR, "ref" STRUCT("$link" VARCHAR), mimeType VARCHAR, size BIGINT, cid VARCHAR))[], media STRUCT("$type" VARCHAR, alt VARCHAR, aspectRatio STRUCT(height BIGINT, width BIGINT), video STRUCT("$type" VARCHAR, "ref" STRUCT("$link" VARCHAR), mimeType VARCHAR, size BIGINT), "external" STRUCT(description VARCHAR, thumb STRUCT("$type" VARCHAR, "ref" STRUCT("$link" VARCHAR), mimeType VARCHAR, size BIGINT), title VARCHAR, uri VARCHAR), images STRUCT(alt VARCHAR, aspectRatio STRUCT(height BIGINT, width BIGINT), image STRUCT("$type" VARCHAR, "ref" STRUCT("$link" VARCHAR), mimeType VARCHAR, size BIGINT))[]), record STRUCT("$type" VARCHAR, record STRUCT(cid VARCHAR, uri VARCHAR, "$type" VARCHAR), cid VARCHAR, uri VARCHAR), "external" STRUCT(description VARCHAR, thumb STRUCT("$type" VARCHAR, "ref" STRUCT("$link" VARCHAR), mimeType VARCHAR, size BIGINT), title VARCHAR, uri VARCHAR), aspectRatio STRUCT(height BIGINT, width BIGINT), video STRUCT("$type" VARCHAR, "ref" STRUCT("$link" VARCHAR), mimeType VARCHAR, size BIGINT), alt VARCHAR, captions STRUCT(file STRUCT("$type" VARCHAR, "ref" STRUCT("$link" VARCHAR), mimeType VARCHAR, size BIGINT), lang VARCHAR)[]), facets STRUCT(features STRUCT("$type" VARCHAR, tag VARCHAR, uri VARCHAR, did VARCHAR)[], "index" STRUCT(byteEnd BIGINT, byteStart BIGINT))[], langs VARCHAR[], "text" VARCHAR, reply STRUCT(parent STRUCT(cid VARCHAR, uri VARCHAR, "$type" VARCHAR), root STRUCT(cid VARCHAR, uri VARCHAR, "$type" VARCHAR)), labels STRUCT("$type" VARCHAR, "values" STRUCT(val VARCHAR)[]), tags VARCHAR[], entities STRUCT("index" STRUCT("end" BIGINT, "start" BIGINT), "type" VARCHAR, "value" VARCHAR)[]), "text" VARCHAR);
    # EOF

    # printf "schema_query: %s\n" "${schema_query}"
    if ! duckdb "${db_path}" < <(printf "%s\n" "${schema_query}"); then
        return 1
    fi
    return 0
}

export_json_file() {
    local db
    local file_json
    local export_query
    declare -a cmd
    local time_start
    local time_stop

    db=$1
    file_json=$2
    time_start="$(TZ=UTC date -I)T00:00:00"
    time_stop="$(TZ=UTC date -I)T23:59:59"
    read -r -d '' export_query <<- EOF
        select json_extract(feedpost, '$.did') as did,
        json_extract(feedpost, '$.cid') as cid,
        json_extract(feedpost, '$.feedpost.createdAt') as created_at,
        json_extract(feedpost, '$.feedpost.text') as text
        from posts
        where json_extract(feedpost, '$.feedpost.createdAt') >= '$time_start'
        and json_extract(feedpost, '$.feedpost.createdAt') <= '$time_stop'
        and json_extract(feedpost, '$.feedpost.langs') = '["en"]'
        order by rowid
EOF

    cmd+=(sqlite3 -readonly -json)
    cmd+=("$db")
    # cmd+=("select json_extract(feedpost, '$.did') as did, json_extract(feedpost, '$.cid') as cid, json_extract(feedpost, '$.feedpost.createdAt') as created_at, json_extract(feedpost, '$.feedpost.text') as text from posts where json_extract(feedpost, '$.feedpost.createdAt') >= '$time_start' and json_extract(feedpost, '$.feedpost.createdAt') <= '$time_stop' and json_extract(feedpost, '$.feedpost.langs') = '[\"en\"]' order by rowid")
    cmd+=("${export_query}")

    "${cmd[@]}" > "$file_json"
}

import_json() {
    local file_json
    local file_duck
    local file_duck_tmp
    local partial_lines
    local schema_query
    local insert_query
    declare -a args

    # parse options
    while [[ $# -gt 0 ]]; do
        case $1 in
            "--partial")
                shift
                partial_lines=$1
                shift
                ;;
            *)
                args+=("$1")
                shift
                ;;
        esac
    done

    file_json="${args[0]}"
    file_duck="${args[1]}"
    file_duck_tmp="${args[2]}"

    # look for previously created database with schema
    require_file "${file_duck_tmp}"

    # partail import
    if (( partial_lines > 0 )); then
        file_json_partial="${file_json}.partial"

        printf "reading last %s lines from %s ... " "${partial_lines}" "${file_json}"
        if tail -n "${partial_lines}" "${file_json}" > "${file_json_partial}"; then
            # use partial file
            file_json="${file_json_partial}"
        fi
    fi
    # sample entire file before processing to avoid any unexpected fields
    # insert_query=$(printf "insert into posts select * from read_json('%s', sample_size = -1)" "${file_json}")
    insert_query=$(printf "insert into posts select did, cid, created_at, text from read_json_auto('%s')" "${file_json}")
    if ! duckdb "${file_duck_tmp}" "${insert_query}" &>/dev/null; then
        printf "insert_query: %s\n" "${insert_query}"
        return 1
    fi
    # replace old file
    mv "${file_duck_tmp}" "${file_duck}"
}

file_info() {
    for f in "$@"; do
        printf "%s %s bytes\n" "${f}" "$(stat -c "%s" "${f}")"
    done
}

fts_index() {
    local file_duck
    local cmd
    file_duck=$1

    cmd=$(printf "pragma create_fts_index(posts, cid, text, stemmer = 'porter', stopwords = 'english', ignore = '(\\.|[^a-z])+', strip_accents = 1, lower = 1, overwrite = 0)")
    duckdb "${file_duck}" "${cmd}" &>/dev/null
}

# check for help args
for arg in "$@"; do
    if [[ "${arg}" == "--help" ]] || [[ "${arg}" == "-h" ]]; then
        usage
    fi
done

declare -a args
partial_lines=0

while [[ $# -gt 0 ]]; do
    case $1 in
        "--partial")
            shift
            partial_lines=$1
            shift
            ;;
        *)
            args+=("$1")
            shift
            ;;
    esac
done

require_bin duckdb

sqlite_source="data/jetstream.sqlite3"
json_source=${args[0]:-"data/jetstream.json"}
duckdb_dest=${args[1]:-"data/jetstream.duckdb"}
duckdb_dest_tmp="${duckdb_dest}.tmp"

printf "%s starting build\n" "$(TZ=UTC date)"

# remove database before rebuild if present
# if [[ -f "${duckdb_dest}" ]]; then
#     rm "${duckdb_dest}"
# fi

printf "create database and write schema ... "
if ! create_database "${duckdb_dest_tmp}"; then
    printf "error\n"
    exit 1
fi
printf "ok\n"

require_file "${duckdb_dest_tmp}"
require_file "${sqlite_source}"

printf "export json to file ... "
if ! export_json_file "${sqlite_source}" "${json_source}"; then
    printf "error\n"
    exit 1
fi
printf "ok\n"

require_file "${json_source}"

printf "importing %s to %s ... " "${json_source}" "${duckdb_dest}"
if ! import_json --partial "${partial_lines}" "${json_source}" "${duckdb_dest}" "${duckdb_dest_tmp}"; then
    printf "error\n"
    exit 1
fi
printf "ok\n"

printf "implementing fts ... "
if ! fts_index "${duckdb_dest}"; then
    printf "error\n"
    exit 1
fi
printf "ok\n"

printf "removing temp file %s ... " "${json_source}"
if ! rm "${json_source}"; then
    printf "error\n"
    exit 1
fi
printf "ok\n"

printf "%s build complete\n" "$(TZ=UTC date)"
# file_info "${json_source}" "${duckdb_dest}"
